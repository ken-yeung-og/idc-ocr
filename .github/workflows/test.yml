name: Test IDC OCR System

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to test'
        required: true
        default: 'dev'
        type: choice
        options:
        - dev
        - staging
        - prod
      test_type:
        description: 'Type of test to run'
        required: true
        default: 'full'
        type: choice
        options:
        - connectivity
        - full
        - performance
  schedule:
    # Run tests daily at 6 AM UTC
    - cron: '0 6 * * *'

env:
  AWS_REGION: us-east-1
  TERRAGRUNT_VERSION: 0.54.8

jobs:
  test-connectivity:
    name: Test AWS Services Connectivity
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'dev' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terragrunt
        run: |
          wget -O terragrunt https://github.com/gruntwork-io/terragrunt/releases/download/v${{ env.TERRAGRUNT_VERSION }}/terragrunt_linux_amd64
          chmod +x terragrunt
          sudo mv terragrunt /usr/local/bin/

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set Environment Variables
        run: |
          ENV_NAME="${{ github.event.inputs.environment || 'dev' }}"
          echo "ENVIRONMENT=$ENV_NAME" >> $GITHUB_ENV

      - name: Check Deployment Exists
        id: deployment
        working-directory: infra
        run: |
          if terragrunt output s3_bucket_name 2>/dev/null; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "s3_bucket=$(terragrunt output -raw s3_bucket_name)" >> $GITHUB_OUTPUT
            echo "dynamodb_table=$(terragrunt output -raw dynamodb_table_name)" >> $GITHUB_OUTPUT
            echo "lambda_function=$(terragrunt output -raw lambda_function_name)" >> $GITHUB_OUTPUT
            echo "✅ Deployment found for environment: ${{ env.ENVIRONMENT }}"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "❌ No deployment found for environment: ${{ env.ENVIRONMENT }}"
          fi

      - name: Test AWS Services
        if: steps.deployment.outputs.exists == 'true'
        run: |
          echo "Testing AWS services connectivity..."
          
          # Test S3 access
          echo "🧪 Testing S3 access..."
          if aws s3 ls s3://${{ steps.deployment.outputs.s3_bucket }}/ --quiet; then
            echo "✅ S3 bucket access working"
            S3_STATUS="✅ PASS"
          else
            echo "❌ S3 bucket access failed"
            S3_STATUS="❌ FAIL"
          fi
          
          # Test DynamoDB access
          echo "🧪 Testing DynamoDB access..."
          if aws dynamodb describe-table --table-name ${{ steps.deployment.outputs.dynamodb_table }} --region ${{ env.AWS_REGION }} --query "Table.TableName" --output text > /dev/null; then
            echo "✅ DynamoDB table access working"
            DYNAMODB_STATUS="✅ PASS"
          else
            echo "❌ DynamoDB table access failed"
            DYNAMODB_STATUS="❌ FAIL"
          fi
          
          # Test Lambda function
          echo "🧪 Testing Lambda function..."
          LAMBDA_STATE=$(aws lambda get-function --function-name ${{ steps.deployment.outputs.lambda_function }} --region ${{ env.AWS_REGION }} --query "Configuration.State" --output text)
          if [ "$LAMBDA_STATE" = "Active" ]; then
            echo "✅ Lambda function is active"
            LAMBDA_STATUS="✅ PASS"
          else
            echo "❌ Lambda function state: $LAMBDA_STATE"
            LAMBDA_STATUS="❌ FAIL"
          fi
          
          # Test Bedrock access
          echo "🧪 Testing Bedrock access..."
          if aws bedrock list-foundation-models --region ${{ env.AWS_REGION }} --query 'modelSummaries[?contains(modelId, `claude-3`)].modelId' --output text | grep -q claude-3; then
            echo "✅ Bedrock access working"
            BEDROCK_STATUS="✅ PASS"
          else
            echo "⚠️ Bedrock access limited or unavailable"
            BEDROCK_STATUS="⚠️ LIMITED"
          fi
          
          # Create summary
          echo "## 🔍 Connectivity Test Results" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ env.ENVIRONMENT }}" >> $GITHUB_STEP_SUMMARY
          echo "**Test Date:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Service | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| S3 | $S3_STATUS |" >> $GITHUB_STEP_SUMMARY
          echo "| DynamoDB | $DYNAMODB_STATUS |" >> $GITHUB_STEP_SUMMARY
          echo "| Lambda | $LAMBDA_STATUS |" >> $GITHUB_STEP_SUMMARY
          echo "| Bedrock | $BEDROCK_STATUS |" >> $GITHUB_STEP_SUMMARY

      - name: No Deployment Found
        if: steps.deployment.outputs.exists == 'false'
        run: |
          echo "## ❌ Test Failed" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ env.ENVIRONMENT }}" >> $GITHUB_STEP_SUMMARY
          echo "**Issue:** No deployment found" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Please deploy the system first using the deployment workflow." >> $GITHUB_STEP_SUMMARY
          exit 1

  test-full-pipeline:
    name: Test Full Document Processing Pipeline
    runs-on: ubuntu-latest
    needs: test-connectivity
    if: (github.event.inputs.test_type == 'full' || github.event.inputs.test_type == 'performance') || github.event_name == 'schedule'
    environment: ${{ github.event.inputs.environment || 'dev' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terragrunt
        run: |
          wget -O terragrunt https://github.com/gruntwork-io/terragrunt/releases/download/v${{ env.TERRAGRUNT_VERSION }}/terragrunt_linux_amd64
          chmod +x terragrunt
          sudo mv terragrunt /usr/local/bin/

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set Environment Variables
        run: |
          ENV_NAME="${{ github.event.inputs.environment || 'dev' }}"
          echo "ENVIRONMENT=$ENV_NAME" >> $GITHUB_ENV

      - name: Get Deployment Info
        id: deployment
        working-directory: infra
        run: |
          echo "s3_bucket=$(terragrunt output -raw s3_bucket_name)" >> $GITHUB_OUTPUT
          echo "dynamodb_table=$(terragrunt output -raw dynamodb_table_name)" >> $GITHUB_OUTPUT
          echo "lambda_function=$(terragrunt output -raw lambda_function_name)" >> $GITHUB_OUTPUT

      - name: Create Test Documents
        run: |
          # Create a simple text document
          cat > test-simple.txt << 'EOF'
          # Simple Test Document
          
          This is a simple test document for the IDC OCR system.
          
          ## Test Information
          - Test Type: Simple Text
          - Environment: ${{ env.ENVIRONMENT }}
          - Workflow: ${{ github.workflow }}
          - Run Number: ${{ github.run_number }}
          
          The quick brown fox jumps over the lazy dog.
          This sentence contains every letter of the alphabet.
          EOF
          
          # Create a more complex document
          cat > test-complex.txt << 'EOF'
          # Complex Test Document - IDC OCR System
          
          ## Executive Summary
          This document contains multiple sections to test the advanced capabilities of the Bedrock Data Automation system.
          
          ## Table Example
          | Metric | Value | Status |
          |--------|-------|--------|
          | Accuracy | 95% | ✅ |
          | Speed | 60s avg | ⚠️ |
          | Cost | $0.05/doc | ✅ |
          
          ## Technical Specifications
          - **AI Model**: Claude 3 Sonnet with Vision
          - **Processing**: Bedrock Data Automation
          - **Storage**: DynamoDB with GSI
          - **Triggers**: S3 Event Notifications
          
          ## Sample Code Block
          ```python
          import boto3
          
          def process_document(bucket, key):
              # Process document with Bedrock
              return extract_text_with_ai(bucket, key)
          ```
          
          ## Conclusion
          This test document validates the system's ability to process complex structured content with tables, code blocks, and various formatting elements.
          EOF

      - name: Upload Test Documents
        id: upload
        run: |
          echo "Uploading test documents..."
          
          # Upload simple document
          aws s3 cp test-simple.txt s3://${{ steps.deployment.outputs.s3_bucket }}/test-simple-${{ github.run_number }}.txt
          
          # Upload complex document
          aws s3 cp test-complex.txt s3://${{ steps.deployment.outputs.s3_bucket }}/test-complex-${{ github.run_number }}.txt
          
          echo "upload_time=$(date -u +%s)" >> $GITHUB_OUTPUT
          echo "✅ Test documents uploaded successfully"

      - name: Wait for Processing
        run: |
          echo "Waiting for document processing..."
          echo "This may take 2-3 minutes for AI processing to complete..."
          sleep 180  # Wait 3 minutes for processing

      - name: Check Processing Results
        id: results
        run: |
          echo "Checking processing results..."
          
          # Get item count
          ITEM_COUNT=$(aws dynamodb scan --table-name ${{ steps.deployment.outputs.dynamodb_table }} --region ${{ env.AWS_REGION }} --select "COUNT" --query "Count" --output text)
          echo "Total items in DynamoDB: $ITEM_COUNT"
          
          # Get recent items (uploaded in last 10 minutes)
          RECENT_TIME=$(($(date -u +%s) - 600))
          RECENT_ITEMS=$(aws dynamodb scan \
            --table-name ${{ steps.deployment.outputs.dynamodb_table }} \
            --region ${{ env.AWS_REGION }} \
            --filter-expression "upload_timestamp > :time" \
            --expression-attribute-values "{\":time\":{\"N\":\"$RECENT_TIME\"}}" \
            --select "COUNT" \
            --query "Count" \
            --output text)
          
          echo "Recent items: $RECENT_ITEMS"
          echo "item_count=$ITEM_COUNT" >> $GITHUB_OUTPUT
          echo "recent_items=$RECENT_ITEMS" >> $GITHUB_OUTPUT
          
          if [ "$RECENT_ITEMS" -ge 1 ]; then
            echo "✅ Documents processed successfully"
            
            # Get latest processed item details
            LATEST_ITEM=$(aws dynamodb scan \
              --table-name ${{ steps.deployment.outputs.dynamodb_table }} \
              --region ${{ env.AWS_REGION }} \
              --filter-expression "upload_timestamp > :time" \
              --expression-attribute-values "{\":time\":{\"N\":\"$RECENT_TIME\"}}" \
              --limit 1 \
              --query "Items[0]" \
              --output json)
            
            echo "latest_item<<EOF" >> $GITHUB_OUTPUT
            echo "$LATEST_ITEM" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
            
            # Extract metrics
            TEXT_LENGTH=$(echo "$LATEST_ITEM" | jq -r '.text_length.N // "0"')
            SUMMARY_LENGTH=$(echo "$LATEST_ITEM" | jq -r '.summary_length.N // "0"')
            
            echo "text_length=$TEXT_LENGTH" >> $GITHUB_OUTPUT
            echo "summary_length=$SUMMARY_LENGTH" >> $GITHUB_OUTPUT
            
          else
            echo "❌ No recent processing detected"
          fi

      - name: Verify Processing Quality
        if: steps.results.outputs.recent_items >= 1
        run: |
          echo "Verifying processing quality..."
          
          TEXT_LENGTH=${{ steps.results.outputs.text_length }}
          SUMMARY_LENGTH=${{ steps.results.outputs.summary_length }}
          
          echo "Text length: $TEXT_LENGTH characters"
          echo "Summary length: $SUMMARY_LENGTH characters"
          
          # Quality checks
          QUALITY_SCORE=0
          
          if [ "$TEXT_LENGTH" -gt 100 ]; then
            echo "✅ Text extraction successful (>100 chars)"
            QUALITY_SCORE=$((QUALITY_SCORE + 25))
          else
            echo "⚠️ Text extraction may be incomplete (<100 chars)"
          fi
          
          if [ "$SUMMARY_LENGTH" -gt 50 ]; then
            echo "✅ Summary generation successful (>50 chars)"
            QUALITY_SCORE=$((QUALITY_SCORE + 25))
          else
            echo "⚠️ Summary may be incomplete (<50 chars)"
          fi
          
          # Check if summary is reasonable compared to text
          if [ "$SUMMARY_LENGTH" -gt 0 ] && [ "$TEXT_LENGTH" -gt 0 ]; then
            RATIO=$((SUMMARY_LENGTH * 100 / TEXT_LENGTH))
            if [ "$RATIO" -ge 10 ] && [ "$RATIO" -le 50 ]; then
              echo "✅ Summary ratio is reasonable (${RATIO}%)"
              QUALITY_SCORE=$((QUALITY_SCORE + 25))
            else
              echo "⚠️ Summary ratio unusual (${RATIO}%)"
            fi
          fi
          
          # Processing time check (within last 10 minutes)
          PROCESSING_TIME=$(($(date -u +%s) - ${{ steps.upload.outputs.upload_time }}))
          if [ "$PROCESSING_TIME" -le 600 ]; then
            echo "✅ Processing completed in reasonable time (${PROCESSING_TIME}s)"
            QUALITY_SCORE=$((QUALITY_SCORE + 25))
          else
            echo "⚠️ Processing took longer than expected (${PROCESSING_TIME}s)"
          fi
          
          echo "Overall quality score: ${QUALITY_SCORE}/100"
          
          if [ "$QUALITY_SCORE" -ge 75 ]; then
            QUALITY_STATUS="✅ EXCELLENT"
          elif [ "$QUALITY_SCORE" -ge 50 ]; then
            QUALITY_STATUS="⚠️ GOOD"
          else
            QUALITY_STATUS="❌ NEEDS_ATTENTION"
          fi
          
          echo "## 🧪 Full Pipeline Test Results" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ env.ENVIRONMENT }}" >> $GITHUB_STEP_SUMMARY
          echo "**Test Date:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "**Documents Processed:** ${{ steps.results.outputs.recent_items }}" >> $GITHUB_STEP_SUMMARY
          echo "**Quality Score:** ${QUALITY_SCORE}/100" >> $GITHUB_STEP_SUMMARY
          echo "**Overall Status:** $QUALITY_STATUS" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Processing Metrics" >> $GITHUB_STEP_SUMMARY
          echo "- **Text Extracted:** $TEXT_LENGTH characters" >> $GITHUB_STEP_SUMMARY
          echo "- **Summary Generated:** $SUMMARY_LENGTH characters" >> $GITHUB_STEP_SUMMARY
          echo "- **Processing Time:** ${PROCESSING_TIME} seconds" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Latest Processed Document" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          echo '${{ steps.results.outputs.latest_item }}' | jq '.' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Test Failed
        if: steps.results.outputs.recent_items < 1
        run: |
          echo "## ❌ Pipeline Test Failed" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ env.ENVIRONMENT }}" >> $GITHUB_STEP_SUMMARY
          echo "**Issue:** Documents uploaded but not processed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Troubleshooting Steps:" >> $GITHUB_STEP_SUMMARY
          echo "1. Check Lambda function logs" >> $GITHUB_STEP_SUMMARY
          echo "2. Verify S3 event notifications" >> $GITHUB_STEP_SUMMARY
          echo "3. Check Bedrock model access" >> $GITHUB_STEP_SUMMARY
          echo "4. Verify DynamoDB permissions" >> $GITHUB_STEP_SUMMARY
          
          # Check Lambda logs
          echo "Checking Lambda logs for errors..."
          aws logs tail /aws/lambda/${{ steps.deployment.outputs.lambda_function }} --region ${{ env.AWS_REGION }} --since 10m --format short
          
          exit 1

  cleanup-test-data:
    name: Cleanup Test Data
    runs-on: ubuntu-latest
    needs: [test-connectivity, test-full-pipeline]
    if: always() && (github.event.inputs.test_type == 'full' || github.event.inputs.test_type == 'performance' || github.event_name == 'schedule')
    environment: ${{ github.event.inputs.environment || 'dev' }}
    steps:
      - name: Setup Terragrunt
        run: |
          wget -O terragrunt https://github.com/gruntwork-io/terragrunt/releases/download/v${{ env.TERRAGRUNT_VERSION }}/terragrunt_linux_amd64
          chmod +x terragrunt
          sudo mv terragrunt /usr/local/bin/

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Checkout
        uses: actions/checkout@v4

      - name: Get Deployment Info
        id: deployment
        working-directory: infra
        run: |
          if terragrunt output s3_bucket_name 2>/dev/null; then
            echo "s3_bucket=$(terragrunt output -raw s3_bucket_name)" >> $GITHUB_OUTPUT
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Cleanup Test Files
        if: steps.deployment.outputs.exists == 'true'
        run: |
          echo "Cleaning up test files..."
          
          # Remove test files from S3
          aws s3 rm s3://${{ steps.deployment.outputs.s3_bucket }}/ --recursive --exclude "*" --include "test-*${{ github.run_number }}.txt" || true
          aws s3 rm s3://${{ steps.deployment.outputs.s3_bucket }}/ --recursive --exclude "*" --include "github-actions-test-${{ github.run_number }}.txt" || true
          
          echo "✅ Test data cleanup completed" 